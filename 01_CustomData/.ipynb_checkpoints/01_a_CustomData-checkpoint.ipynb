{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成测试数据\n",
    "\n",
    "* 10组每组10张 训练数据\n",
    "    * img_i\n",
    "    * 0~10.png\n",
    "    * trainData_i.dt\n",
    "* 1组10张 测试数据\n",
    "    * imgTest\n",
    "    * testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir\n",
    "import os,sys\n",
    "path = \"./testDir\"\n",
    "if os.path.exists(path):\n",
    "    print('dir exist')\n",
    "else:\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "import os,sys\n",
    "\n",
    "imgW = 28\n",
    "imgH = 28\n",
    "\n",
    "def generalRec():\n",
    "    img = np.ones((imgW,imgH),dtype=np.uint8)\n",
    "    InitX = random.randint(2,imgW-5)\n",
    "    InitY = random.randint(2,imgH-5)\n",
    "    RecW = random.randint(4,imgW-InitX-1)\n",
    "    RecH = random.randint(4,imgH-InitY-1)\n",
    "    cv.rectangle(img,(InitX,InitY),(RecW,RecH),255,1)\n",
    "#     #显示图片\n",
    "#     cv.namedWindow(\"img\")\n",
    "#     cv.imshow(\"img\",img)\n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()\n",
    "    return img\n",
    "\n",
    "\n",
    "    \n",
    "def generalCircle():\n",
    "    img = np.ones((imgW,imgH),dtype=np.uint8)\n",
    "    InitX = random.randint(5,imgW-5)\n",
    "    InitY = random.randint(5,imgH-5)\n",
    "    minDis = min(5,imgW-InitX,imgH-InitY)\n",
    "    r = random.randint(2,minDis)\n",
    "    cv.circle(img,(InitX,InitY),r,255,1)\n",
    "#     #显示图片\n",
    "#     cv.namedWindow(\"img\")\n",
    "#     cv.imshow(\"img\",img)\n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()\n",
    "    return img\n",
    "    \n",
    "\n",
    "def GenerateTrainData(genNum,imageDir,dataFilePath):\n",
    "#     trainDataFile = \"./trainData/trainData_\"+str(index)+\".dt\" \n",
    "    with open(dataFilePath,'w') as f:\n",
    "        for i in range(genNum):\n",
    "            randBoo = random.choice([True,False])\n",
    "            if(randBoo):\n",
    "                # general rec\n",
    "                genImg = generalRec()\n",
    "                lineStr = imageDir+\"/\"+i.__str__()+\".png,0\\n\"\n",
    "                f.write(lineStr)\n",
    "                cv.imwrite(imageDir+\"/\"+i.__str__()+\".png\",genImg)\n",
    "            else:\n",
    "                # general circle\n",
    "                genImg = generalCircle()\n",
    "                lineStr = imageDir+\"/\"+i.__str__()+\".png,1\\n\"\n",
    "                f.write(lineStr)\n",
    "                cv.imwrite(imageDir+\"/\"+i.__str__()+\".png\",genImg)\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "dataDir = \"./trainData\"\n",
    "if os.path.exists(dataDir):\n",
    "    print('DataDir exist')\n",
    "else:\n",
    "    os.makedirs(dataDir)    \n",
    "\n",
    "for i in range(10):\n",
    "    path = \"./img/img_\"+str(i)\n",
    "    if os.path.exists(path):\n",
    "        print('dir exist')\n",
    "    else:\n",
    "        os.makedirs(path)\n",
    "    dataFilePath = \"./trainData/trainData_\"+str(i)+\".dt\" \n",
    "    GenerateTrainData(10,path,dataFilePath)\n",
    "    \n",
    "testImgPath = \"./img/img_test\"\n",
    "if os.path.exists(testImgPath):\n",
    "    print('DataDir exist')\n",
    "else:\n",
    "    os.makedirs(testImgPath)    \n",
    "testDataFilePath = \"./trainData/testData.dt\" \n",
    "GenerateTrainData(10,testImgPath,testDataFilePath)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据读取验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    line = f.readline()\n",
    "    while line:\n",
    "        strSplit=line.split(',',1)\n",
    "        label_input=int(strSplit[1])\n",
    "        print(label_input)\n",
    "        img = cv.imread(strSplit[0],cv.IMREAD_GRAYSCALE)\n",
    "#         print(img)\n",
    "#         npImg = np.reshape(img,(1,784))\n",
    "#         print(npImg)\n",
    "#         cv.namedWindow(\"img\")\n",
    "#         cv.imshow(\"img\",img)\n",
    "#         cv.waitKey(0)\n",
    "#         cv.destroyAllWindows()\n",
    "        line = f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy\n",
    "\n",
    "def readCustomDataFromFile(trainDataPath):\n",
    "    read_img = np.empty((10,1,28,28),dtype='float32')\n",
    "    read_label = np.empty((10,1),dtype='int64')\n",
    "\n",
    "    with open(trainDataPath) as f:\n",
    "        for i in range(10):\n",
    "            line = f.readline()\n",
    "            if line:\n",
    "                strSplit=line.split(',',1)\n",
    "                img = cv.imread(strSplit[0],cv.IMREAD_GRAYSCALE)\n",
    "                read_img[i][0] = img\n",
    "                read_label[i] = int(strSplit[1])\n",
    "            else:\n",
    "                break\n",
    "    print(read_label)\n",
    "    read_img =read_img/255.0*2.0 - 1.0\n",
    "    return read_img,read_label\n",
    "\n",
    "\n",
    "\n",
    "a,b = readCustomDataFromFile('trainData/trainData_1.dt')\n",
    "\n",
    "# http://www.paddlepaddle.org/documentation/docs/zh/1.2/user_guides/howto/prepare_data/reader_cn.html\n",
    "# images = images / 255.0 * 2.0 - 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.empty((32,1),dtype=float)\n",
    "a[0][0]=123\n",
    "# print(a)\n",
    "\n",
    "b =np.empty((1,1,2,2),dtype=float)\n",
    "c =np.empty((2,2),dtype=float)\n",
    "c[0][0] = 1.1\n",
    "c[0][1] = 2.2\n",
    "c[1][0] = 3.3\n",
    "c[1][1] = 4.4\n",
    "b[0][0] = c\n",
    "print(c)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=numpy.random.random(size=(10, 1, 28, 28)).astype('float32')\n",
    "print(a)\n",
    "b=numpy.random.random(size=(10, 1)).astype('int64')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 0, Cost 2.413728\n",
      "Test with Epoch 0, avg_cost: 1.2064870595932007, acc: 0.30000001192092896\n",
      " Batch 1, Cost 1.024712\n",
      "Test with Epoch 1, avg_cost: 0.9445624351501465, acc: 0.5\n",
      " Batch 2, Cost 1.214199\n",
      "Test with Epoch 2, avg_cost: 0.8885771036148071, acc: 0.4000000059604645\n",
      " Batch 3, Cost 1.424419\n",
      "Test with Epoch 3, avg_cost: 0.683829128742218, acc: 0.699999988079071\n",
      " Batch 4, Cost 0.330427\n",
      "Test with Epoch 4, avg_cost: 0.5954464077949524, acc: 0.699999988079071\n",
      " Batch 5, Cost 0.530659\n",
      "Test with Epoch 5, avg_cost: 0.5131652355194092, acc: 0.800000011920929\n",
      " Batch 6, Cost 1.040055\n",
      "Test with Epoch 6, avg_cost: 0.4793611466884613, acc: 0.9000000357627869\n",
      " Batch 7, Cost 0.600359\n",
      "Test with Epoch 7, avg_cost: 0.482517808675766, acc: 0.800000011920929\n",
      " Batch 8, Cost 2.097363\n",
      "Test with Epoch 8, avg_cost: 0.5515785217285156, acc: 0.800000011920929\n",
      " Batch 9, Cost 0.398899\n",
      "Test with Epoch 9, avg_cost: 0.6600465178489685, acc: 0.699999988079071\n",
      "train finsh~~~\n",
      "recognize_digits_convolutional_neural_network.inference.model\n",
      "None\n",
      "Inference result of image/rec.png is: 0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import cv2 as cv\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "PASS_NUM = 5\n",
    "\n",
    "\n",
    "def readCustomDataFromFile(trainDataPath):\n",
    "    read_img = numpy.empty((10,1,28,28),dtype='float32')\n",
    "    read_label = numpy.empty((10,1),dtype='int64')\n",
    "\n",
    "    with open(trainDataPath) as f:\n",
    "        for i in range(10):\n",
    "            line = f.readline()\n",
    "            if line:\n",
    "                strSplit=line.split(',',1)\n",
    "                img = cv.imread(strSplit[0],cv.IMREAD_GRAYSCALE)\n",
    "                read_img[i][0] = img\n",
    "                read_label[i] = int(strSplit[1])\n",
    "            else:\n",
    "                break\n",
    "    read_img =read_img/255.0*2.0 - 1.0\n",
    "    return read_img,read_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_net(hidden, label):\n",
    "    prediction = fluid.layers.fc(input=hidden, size=10, act='softmax')\n",
    "    loss = fluid.layers.cross_entropy(input=prediction, label=label)\n",
    "    avg_loss = fluid.layers.mean(loss)\n",
    "    acc = fluid.layers.accuracy(input=prediction, label=label)\n",
    "    return prediction, avg_loss, acc\n",
    "\n",
    "\n",
    "def multilayer_perceptron(img, label):\n",
    "    img = fluid.layers.fc(input=img, size=200, act='tanh')\n",
    "    hidden = fluid.layers.fc(input=img, size=200, act='tanh')\n",
    "    return loss_net(hidden, label)\n",
    "\n",
    "\n",
    "def softmax_regression(img, label):\n",
    "    return loss_net(img, label)\n",
    "\n",
    "\n",
    "def convolutional_neural_network(img, label):\n",
    "    conv_pool_1 = fluid.nets.simple_img_conv_pool(\n",
    "        input=img,\n",
    "        filter_size=5,\n",
    "        num_filters=20,\n",
    "        pool_size=2,\n",
    "        pool_stride=2,\n",
    "        act=\"relu\")\n",
    "    conv_pool_1 = fluid.layers.batch_norm(conv_pool_1)\n",
    "    conv_pool_2 = fluid.nets.simple_img_conv_pool(\n",
    "        input=conv_pool_1,\n",
    "        filter_size=5,\n",
    "        num_filters=50,\n",
    "        pool_size=2,\n",
    "        pool_stride=2,\n",
    "        act=\"relu\")\n",
    "    return loss_net(conv_pool_2, label)\n",
    "\n",
    "\n",
    "def train(nn_type,\n",
    "          use_cuda,\n",
    "          save_dirname=None,\n",
    "          model_filename=None,\n",
    "          params_filename=None):\n",
    "    if use_cuda and not fluid.core.is_compiled_with_cuda():\n",
    "        return\n",
    "\n",
    "    img = fluid.layers.data(name='img', shape=[1, 28, 28], dtype='float32')\n",
    "    label = fluid.layers.data(name='label', shape=[1], dtype='int64')\n",
    "\n",
    "    if nn_type == 'softmax_regression':\n",
    "        net_conf = softmax_regression\n",
    "    elif nn_type == 'multilayer_perceptron':\n",
    "        net_conf = multilayer_perceptron\n",
    "    else:\n",
    "        net_conf = convolutional_neural_network\n",
    "\n",
    "    prediction, avg_loss, acc = net_conf(img, label)\n",
    "\n",
    "    test_program = fluid.default_main_program().clone(for_test=True)\n",
    "\n",
    "    optimizer = fluid.optimizer.Adam(learning_rate=0.001)\n",
    "    optimizer.minimize(avg_loss)\n",
    "\n",
    "    def train_test(train_test_program):\n",
    "        acc_set = []\n",
    "        avg_loss_set = []\n",
    "        readImg,readLabel = readCustomDataFromFile('trainData/testData.dt')\n",
    "        acc_np, avg_loss_np = exe.run(\n",
    "            test_program,\n",
    "            feed={\n",
    "                \"img\": readImg,\n",
    "                \"label\": readLabel\n",
    "            },\n",
    "            fetch_list=[acc, avg_loss])\n",
    "        acc_set.append(float(acc_np))\n",
    "        avg_loss_set.append(float(avg_loss_np))\n",
    "        # get test acc and loss\n",
    "        acc_val_mean = numpy.array(acc_set).mean()\n",
    "        avg_loss_val_mean = numpy.array(avg_loss_set).mean()\n",
    "        return avg_loss_val_mean, acc_val_mean\n",
    "\n",
    "    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "\n",
    "    exe = fluid.Executor(place)\n",
    "\n",
    "    train_reader = paddle.batch(\n",
    "        paddle.reader.shuffle(paddle.dataset.mnist.train(), buf_size=500),\n",
    "        batch_size=BATCH_SIZE)\n",
    "    test_reader = paddle.batch(\n",
    "        paddle.dataset.mnist.test(), batch_size=BATCH_SIZE)\n",
    "    feeder = fluid.DataFeeder(feed_list=[img, label], place=place)\n",
    "\n",
    "    exe.run(fluid.default_startup_program())\n",
    "    main_program = fluid.default_main_program()\n",
    "    epochs = [epoch_id for epoch_id in range(PASS_NUM)]\n",
    "\n",
    "    lists = []\n",
    "\n",
    "#     for epoch_id in epochs:\n",
    "    for epoch_id in range(10):\n",
    "        trainDataFilePath = 'trainData/trainData_'+str(epoch_id)+'.dt'\n",
    "        readImg,readLabel = readCustomDataFromFile(trainDataFilePath)\n",
    "        metrics = exe.run(\n",
    "            main_program,\n",
    "            feed={\n",
    "                \"img\": readImg,\n",
    "                \"label\": readLabel\n",
    "            },\n",
    "            fetch_list=[avg_loss, acc])\n",
    "\n",
    "        print(\" Batch %d, Cost %f\" % (epoch_id,metrics[0]))\n",
    "\n",
    "            \n",
    "        # test for epoch\n",
    "        avg_loss_val, acc_val = train_test(test_program)\n",
    "        print(\"Test with Epoch %d, avg_cost: %s, acc: %s\" %\n",
    "              (epoch_id, avg_loss_val, acc_val))\n",
    "        lists.append((epoch_id, avg_loss_val, acc_val))\n",
    "        if save_dirname is not None:\n",
    "            fluid.io.save_inference_model(\n",
    "                save_dirname, [\"img\"], [prediction],\n",
    "                exe,\n",
    "                model_filename=model_filename,\n",
    "                params_filename=params_filename)\n",
    "\n",
    "    # find the best pass\n",
    "#     best = sorted(lists, key=lambda list: float(list[1]))[0]\n",
    "#     print('Best pass is %s, testing Avgcost is %s' % (best[0], best[1]))\n",
    "#     print('The classification accuracy is %.2f%%' % (float(best[2]) * 100))\n",
    "\n",
    "\n",
    "def infer(use_cuda,\n",
    "          save_dirname=None,\n",
    "          model_filename=None,\n",
    "          params_filename=None):\n",
    "    if save_dirname is None:\n",
    "        return\n",
    "\n",
    "    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "    exe = fluid.Executor(place)\n",
    "\n",
    "#     def load_image(file):\n",
    "#         im = Image.open(file).convert('L')\n",
    "#         im = im.resize((28, 28), Image.ANTIALIAS)\n",
    "#         im = numpy.array(im).reshape(1, 1, 28, 28).astype(numpy.float32)\n",
    "#         im = im / 255.0 * 2.0 - 1.0\n",
    "#         return im\n",
    "\n",
    "    def load_image(file):\n",
    "        read_img = numpy.empty((1,1,28,28),dtype='float32')\n",
    "        im = cv.imread(file,cv.IMREAD_GRAYSCALE)\n",
    "        read_img[0][0] = im\n",
    "        read_img =read_img/255.0*2.0 - 1.0\n",
    "        return read_img\n",
    "    \n",
    "    tensor_img = load_image('/image/rec.png')\n",
    "#     tensor_img = load_image('/image/circle.png')\n",
    "    \n",
    "\n",
    "    inference_scope = fluid.core.Scope()\n",
    "    with fluid.scope_guard(inference_scope):\n",
    "        # Use fluid.io.load_inference_model to obtain the inference program desc,\n",
    "        # the feed_target_names (the names of variables that will be feeded\n",
    "        # data using feed operators), and the fetch_targets (variables that\n",
    "        # we want to obtain data from using fetch operators).\n",
    "        [inference_program, feed_target_names,\n",
    "         fetch_targets] = fluid.io.load_inference_model(\n",
    "             save_dirname, exe, model_filename, params_filename)\n",
    "\n",
    "        # Construct feed as a dictionary of {feed_target_name: feed_target_data}\n",
    "        # and results will contain a list of data corresponding to fetch_targets.\n",
    "        results = exe.run(\n",
    "            inference_program,\n",
    "            feed={feed_target_names[0]: tensor_img},\n",
    "            fetch_list=fetch_targets)\n",
    "        lab = numpy.argsort(results)\n",
    "        print(\"Inference result of image/rec.png is: %d\" % lab[0][0][-1])\n",
    "\n",
    "\n",
    "def main(use_cuda, nn_type):\n",
    "    model_filename = None\n",
    "    params_filename = None\n",
    "    save_dirname = \"recognize_digits_\" + nn_type + \".inference.model\"\n",
    "\n",
    "    # call train() with is_local argument to run distributed train\n",
    "    train(\n",
    "        nn_type=nn_type,\n",
    "        use_cuda=use_cuda,\n",
    "        save_dirname=save_dirname,\n",
    "        model_filename=model_filename,\n",
    "        params_filename=params_filename)\n",
    "    print('train finsh~~~')\n",
    "    print(save_dirname)\n",
    "    print(model_filename)\n",
    "    infer(\n",
    "        use_cuda=use_cuda,\n",
    "        save_dirname=save_dirname,\n",
    "        model_filename=model_filename,\n",
    "        params_filename=params_filename)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    use_cuda = True\n",
    "    #predict = 'softmax_regression' # uncomment for Softmax\n",
    "    #predict = 'multilayer_perceptron' # uncomment for MLP\n",
    "    predict = 'convolutional_neural_network'  # uncomment for LeNet5\n",
    "    main(use_cuda=use_cuda, nn_type=predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 记录\n",
    "* 运行第二次的时候会报错\n",
    "    * Restart Kernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
