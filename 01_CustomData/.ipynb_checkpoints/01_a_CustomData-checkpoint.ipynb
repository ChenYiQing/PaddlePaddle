{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "\n",
    "imgW = 28\n",
    "imgH = 28\n",
    "\n",
    "def generalRec():\n",
    "    img = np.ones((imgW,imgH),dtype=np.uint8)\n",
    "    InitX = random.randint(2,imgW-5)\n",
    "    InitY = random.randint(2,imgH-5)\n",
    "    RecW = random.randint(4,imgW-InitX-1)\n",
    "    RecH = random.randint(4,imgH-InitY-1)\n",
    "    cv.rectangle(img,(InitX,InitY),(RecW,RecH),255,1)\n",
    "#     #显示图片\n",
    "#     cv.namedWindow(\"img\")\n",
    "#     cv.imshow(\"img\",img)\n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()\n",
    "    return img\n",
    "\n",
    "\n",
    "    \n",
    "def generalCircle():\n",
    "    img = np.ones((imgW,imgH),dtype=np.uint8)\n",
    "    InitX = random.randint(5,imgW-5)\n",
    "    InitY = random.randint(5,imgH-5)\n",
    "    minDis = min(5,imgW-InitX,imgH-InitY)\n",
    "    r = random.randint(2,minDis)\n",
    "    cv.circle(img,(InitX,InitY),r,255,1)\n",
    "#     #显示图片\n",
    "#     cv.namedWindow(\"img\")\n",
    "#     cv.imshow(\"img\",img)\n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()\n",
    "    return img\n",
    "    \n",
    "\n",
    "def GenerateTrainData(genNum):\n",
    "    with open('trainData.dt','w') as f:\n",
    "        for i in range(genNum):\n",
    "            randBoo = random.choice([True,False])\n",
    "            if(randBoo):\n",
    "                # general rec\n",
    "                genImg = generalRec()\n",
    "                lineStr = \"./img/\"+i.__str__()+\".png,0\\n\"\n",
    "                f.write(lineStr)\n",
    "                cv.imwrite(\"./img/\"+i.__str__()+\".png\",genImg)\n",
    "            else:\n",
    "                # general circle\n",
    "                genImg = generalCircle()\n",
    "                lineStr = \"./img/\"+i.__str__()+\".png,1\\n\"\n",
    "                f.write(lineStr)\n",
    "                cv.imwrite(\"./img/\"+i.__str__()+\".png\",genImg)\n",
    "            \n",
    "        \n",
    "\n",
    "GenerateTrainData(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据读取验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    line = f.readline()\n",
    "    while line:\n",
    "        strSplit=line.split(',',1)\n",
    "        label_input=int(strSplit[1])\n",
    "        print(label_input)\n",
    "        img = cv.imread(strSplit[0],cv.IMREAD_GRAYSCALE)\n",
    "#         print(img)\n",
    "#         npImg = np.reshape(img,(1,784))\n",
    "#         print(npImg)\n",
    "#         cv.namedWindow(\"img\")\n",
    "#         cv.imshow(\"img\",img)\n",
    "#         cv.waitKey(0)\n",
    "#         cv.destroyAllWindows()\n",
    "        line = f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "[[-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "   1.         -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686  1.          1.\n",
      "  -0.99215686  1.          1.         -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686  1.         -0.99215686\n",
      "  -0.99215686 -0.99215686  1.         -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686  1.         -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686  1.         -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686  1.         -0.99215686\n",
      "  -0.99215686 -0.99215686  1.         -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686  1.          1.\n",
      "  -0.99215686  1.          1.         -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "   1.         -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]\n",
      " [-0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "  -0.99215686 -0.99215686 -0.99215686 -0.99215686]]\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy\n",
    "\n",
    "def readCustomDataFromFile():\n",
    "    read_img = np.empty((10,1,28,28),dtype='float32')\n",
    "    read_label = np.empty((10,1),dtype='int64')\n",
    "\n",
    "    with open('trainData.dt') as f:\n",
    "        for i in range(10):\n",
    "            line = f.readline()\n",
    "            if line:\n",
    "                strSplit=line.split(',',1)\n",
    "                img = cv.imread(strSplit[0],cv.IMREAD_GRAYSCALE)\n",
    "                read_img[i][0] = img\n",
    "                read_label[i] = int(strSplit[1])\n",
    "            else:\n",
    "                break\n",
    "#     print(read_label)\n",
    "    read_img =read_img/255.0*2.0 - 1.0\n",
    "#     print(read_img[0][0])\n",
    "    return read_img,read_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# http://www.paddlepaddle.org/documentation/docs/zh/1.2/user_guides/howto/prepare_data/reader_cn.html\n",
    "# images = images / 255.0 * 2.0 - 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1 2.2]\n",
      " [3.3 4.4]]\n",
      "[[[[1.1 2.2]\n",
      "   [3.3 4.4]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.empty((32,1),dtype=float)\n",
    "a[0][0]=123\n",
    "# print(a)\n",
    "\n",
    "b =np.empty((1,1,2,2),dtype=float)\n",
    "c =np.empty((2,2),dtype=float)\n",
    "c[0][0] = 1.1\n",
    "c[0][1] = 2.2\n",
    "c[1][0] = 3.3\n",
    "c[1][1] = 4.4\n",
    "b[0][0] = c\n",
    "print(c)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.5743485  0.1542304  0.46041253 ... 0.01405484 0.7681839\n",
      "    0.91006595]\n",
      "   [0.07079032 0.52942073 0.58476466 ... 0.80471116 0.7650902\n",
      "    0.49796796]\n",
      "   [0.05474285 0.73468435 0.95081544 ... 0.6336486  0.44312868\n",
      "    0.62507457]\n",
      "   ...\n",
      "   [0.34583393 0.48112157 0.7498993  ... 0.85645497 0.55139595\n",
      "    0.85465765]\n",
      "   [0.6430424  0.40432027 0.36038673 ... 0.8143612  0.7898529\n",
      "    0.9005755 ]\n",
      "   [0.20034078 0.6497024  0.7358393  ... 0.8011473  0.76923084\n",
      "    0.7583868 ]]]\n",
      "\n",
      "\n",
      " [[[0.2696169  0.7252207  0.8609901  ... 0.7053268  0.5587071\n",
      "    0.976757  ]\n",
      "   [0.3425273  0.8880452  0.93617094 ... 0.952874   0.91059005\n",
      "    0.7334705 ]\n",
      "   [0.9086374  0.3089654  0.9001433  ... 0.17096762 0.975254\n",
      "    0.16174565]\n",
      "   ...\n",
      "   [0.2508163  0.5621683  0.00435819 ... 0.5908544  0.19540736\n",
      "    0.9052826 ]\n",
      "   [0.7064105  0.7575865  0.69314206 ... 0.29350308 0.9019232\n",
      "    0.6938384 ]\n",
      "   [0.22743794 0.29523057 0.94935906 ... 0.88363945 0.7548858\n",
      "    0.91456854]]]\n",
      "\n",
      "\n",
      " [[[0.24138166 0.00438837 0.2748139  ... 0.34095022 0.6842521\n",
      "    0.21803145]\n",
      "   [0.5761044  0.5194127  0.93529946 ... 0.93066794 0.9274742\n",
      "    0.06590096]\n",
      "   [0.35243767 0.2610739  0.64578307 ... 0.95735466 0.10958937\n",
      "    0.4907817 ]\n",
      "   ...\n",
      "   [0.2738782  0.04385226 0.78061765 ... 0.7557912  0.6974292\n",
      "    0.9626357 ]\n",
      "   [0.1410117  0.137621   0.00187277 ... 0.9440285  0.65067536\n",
      "    0.46847573]\n",
      "   [0.6174615  0.3835266  0.20202816 ... 0.1945634  0.12382089\n",
      "    0.09248836]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.86338973 0.7089666  0.75369906 ... 0.42788473 0.11866655\n",
      "    0.3712459 ]\n",
      "   [0.13161263 0.89520884 0.22858547 ... 0.1334259  0.21258324\n",
      "    0.97375685]\n",
      "   [0.77494985 0.4588593  0.94698334 ... 0.8900965  0.08037092\n",
      "    0.7285405 ]\n",
      "   ...\n",
      "   [0.05579065 0.33758357 0.6726291  ... 0.90544736 0.0539041\n",
      "    0.2771826 ]\n",
      "   [0.48645478 0.83272064 0.427031   ... 0.54524714 0.48998067\n",
      "    0.36447552]\n",
      "   [0.7314355  0.47898853 0.9696414  ... 0.11565571 0.3307566\n",
      "    0.64555496]]]\n",
      "\n",
      "\n",
      " [[[0.7410532  0.5343564  0.2603672  ... 0.6162261  0.9556042\n",
      "    0.6156296 ]\n",
      "   [0.9844752  0.19525045 0.21578097 ... 0.29562277 0.16282384\n",
      "    0.28613466]\n",
      "   [0.6029869  0.7162152  0.6339083  ... 0.85411185 0.2451308\n",
      "    0.18049571]\n",
      "   ...\n",
      "   [0.5794007  0.8908503  0.8048623  ... 0.0425186  0.554163\n",
      "    0.3318058 ]\n",
      "   [0.20758434 0.74394304 0.8409095  ... 0.74137664 0.8092073\n",
      "    0.04437177]\n",
      "   [0.8461162  0.18115517 0.06315243 ... 0.66935515 0.6084238\n",
      "    0.99950945]]]\n",
      "\n",
      "\n",
      " [[[0.14682916 0.19232398 0.85868657 ... 0.6925588  0.24099791\n",
      "    0.4293412 ]\n",
      "   [0.36702606 0.26836717 0.3367235  ... 0.67683655 0.22316547\n",
      "    0.5261321 ]\n",
      "   [0.11487561 0.27457148 0.48762298 ... 0.2833545  0.13185975\n",
      "    0.260602  ]\n",
      "   ...\n",
      "   [0.81990784 0.30206522 0.6634495  ... 0.20122837 0.22936681\n",
      "    0.14965214]\n",
      "   [0.9529989  0.3740701  0.87893105 ... 0.1120887  0.99546856\n",
      "    0.98766017]\n",
      "   [0.21218303 0.1319363  0.86233747 ... 0.19296408 0.5945471\n",
      "    0.18752168]]]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "a=numpy.random.random(size=(10, 1, 28, 28)).astype('float32')\n",
    "print(a)\n",
    "b=numpy.random.random(size=(10, 1)).astype('int64')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 0, Cost 2.613351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-97bc5d72e842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;31m#predict = 'multilayer_perceptron' # uncomment for MLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'convolutional_neural_network'\u001b[0m  \u001b[0;31m# uncomment for LeNet5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-97bc5d72e842>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(use_cuda, nn_type)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0msave_dirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_dirname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mmodel_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         params_filename=params_filename)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-97bc5d72e842>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(use_cuda, save_dirname, model_filename, params_filename)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mcur_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0mtensor_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/image/infer_3.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "#   Copyright (c) 2018 PaddlePaddle Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import cv2 as cv\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "PASS_NUM = 5\n",
    "\n",
    "\n",
    "def readCustomDataFromFile():\n",
    "    read_img = numpy.empty((10,1,28,28),dtype='float32')\n",
    "    read_label = numpy.empty((10,1),dtype='int64')\n",
    "\n",
    "    with open('trainData.dt') as f:\n",
    "        for i in range(10):\n",
    "            line = f.readline()\n",
    "            if line:\n",
    "                strSplit=line.split(',',1)\n",
    "                img = cv.imread(strSplit[0],cv.IMREAD_GRAYSCALE)\n",
    "                read_img[i][0] = img\n",
    "                read_label[i] = int(strSplit[1])\n",
    "            else:\n",
    "                break\n",
    "#     print(read_label)\n",
    "    read_img =read_img/255.0*2.0 - 1.0\n",
    "#     print(read_img[0][0])\n",
    "    return read_img,read_label\n",
    "\n",
    "\n",
    "\n",
    "def loss_net(hidden, label):\n",
    "    prediction = fluid.layers.fc(input=hidden, size=10, act='softmax')\n",
    "    loss = fluid.layers.cross_entropy(input=prediction, label=label)\n",
    "    avg_loss = fluid.layers.mean(loss)\n",
    "    acc = fluid.layers.accuracy(input=prediction, label=label)\n",
    "    return prediction, avg_loss, acc\n",
    "\n",
    "\n",
    "def multilayer_perceptron(img, label):\n",
    "    img = fluid.layers.fc(input=img, size=200, act='tanh')\n",
    "    hidden = fluid.layers.fc(input=img, size=200, act='tanh')\n",
    "    return loss_net(hidden, label)\n",
    "\n",
    "\n",
    "def softmax_regression(img, label):\n",
    "    return loss_net(img, label)\n",
    "\n",
    "\n",
    "def convolutional_neural_network(img, label):\n",
    "    conv_pool_1 = fluid.nets.simple_img_conv_pool(\n",
    "        input=img,\n",
    "        filter_size=5,\n",
    "        num_filters=20,\n",
    "        pool_size=2,\n",
    "        pool_stride=2,\n",
    "        act=\"relu\")\n",
    "    conv_pool_1 = fluid.layers.batch_norm(conv_pool_1)\n",
    "    conv_pool_2 = fluid.nets.simple_img_conv_pool(\n",
    "        input=conv_pool_1,\n",
    "        filter_size=5,\n",
    "        num_filters=50,\n",
    "        pool_size=2,\n",
    "        pool_stride=2,\n",
    "        act=\"relu\")\n",
    "    return loss_net(conv_pool_2, label)\n",
    "\n",
    "\n",
    "def train(nn_type,\n",
    "          use_cuda,\n",
    "          save_dirname=None,\n",
    "          model_filename=None,\n",
    "          params_filename=None):\n",
    "    if use_cuda and not fluid.core.is_compiled_with_cuda():\n",
    "        return\n",
    "\n",
    "    img = fluid.layers.data(name='img', shape=[1, 28, 28], dtype='float32')\n",
    "    label = fluid.layers.data(name='label', shape=[1], dtype='int64')\n",
    "\n",
    "    if nn_type == 'softmax_regression':\n",
    "        net_conf = softmax_regression\n",
    "    elif nn_type == 'multilayer_perceptron':\n",
    "        net_conf = multilayer_perceptron\n",
    "    else:\n",
    "        net_conf = convolutional_neural_network\n",
    "\n",
    "    prediction, avg_loss, acc = net_conf(img, label)\n",
    "\n",
    "    test_program = fluid.default_main_program().clone(for_test=True)\n",
    "\n",
    "    optimizer = fluid.optimizer.Adam(learning_rate=0.001)\n",
    "    optimizer.minimize(avg_loss)\n",
    "\n",
    "    def train_test(train_test_program, train_test_feed, train_test_reader):\n",
    "        acc_set = []\n",
    "        avg_loss_set = []\n",
    "        for test_data in train_test_reader():\n",
    "            acc_np, avg_loss_np = exe.run(\n",
    "                program=train_test_program,\n",
    "                feed=train_test_feed.feed(test_data),\n",
    "                fetch_list=[acc, avg_loss])\n",
    "            acc_set.append(float(acc_np))\n",
    "            avg_loss_set.append(float(avg_loss_np))\n",
    "        # get test acc and loss\n",
    "        acc_val_mean = numpy.array(acc_set).mean()\n",
    "        avg_loss_val_mean = numpy.array(avg_loss_set).mean()\n",
    "        return avg_loss_val_mean, acc_val_mean\n",
    "\n",
    "    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "\n",
    "    exe = fluid.Executor(place)\n",
    "\n",
    "    train_reader = paddle.batch(\n",
    "        paddle.reader.shuffle(paddle.dataset.mnist.train(), buf_size=500),\n",
    "        batch_size=BATCH_SIZE)\n",
    "    test_reader = paddle.batch(\n",
    "        paddle.dataset.mnist.test(), batch_size=BATCH_SIZE)\n",
    "    feeder = fluid.DataFeeder(feed_list=[img, label], place=place)\n",
    "\n",
    "    exe.run(fluid.default_startup_program())\n",
    "    main_program = fluid.default_main_program()\n",
    "    epochs = [epoch_id for epoch_id in range(PASS_NUM)]\n",
    "\n",
    "    lists = []\n",
    "\n",
    "#     for epoch_id in epochs:\n",
    "    for epoch_id in range(1):\n",
    "        readImg,readLabel = readCustomDataFromFile()\n",
    "        metrics = exe.run(\n",
    "            main_program,\n",
    "            feed={\n",
    "                \"img\": readImg,\n",
    "                \"label\": readLabel\n",
    "            },\n",
    "            fetch_list=[avg_loss, acc])\n",
    "\n",
    "        print(\" Batch %d, Cost %f\" % (epoch_id,metrics[0]))\n",
    "\n",
    "            \n",
    "        # test for epoch\n",
    "#         avg_loss_val, acc_val = train_test(\n",
    "#             train_test_program=test_program,\n",
    "#             train_test_reader=test_reader,\n",
    "#             train_test_feed=feeder)\n",
    "\n",
    "#         print(\"Test with Epoch %d, avg_cost: %s, acc: %s\" %\n",
    "#               (epoch_id, avg_loss_val, acc_val))\n",
    "#         lists.append((epoch_id, avg_loss_val, acc_val))\n",
    "#         if save_dirname is not None:\n",
    "#             fluid.io.save_inference_model(\n",
    "#                 save_dirname, [\"img\"], [prediction],\n",
    "#                 exe,\n",
    "#                 model_filename=model_filename,\n",
    "#                 params_filename=params_filename)\n",
    "\n",
    "    # find the best pass\n",
    "#     best = sorted(lists, key=lambda list: float(list[1]))[0]\n",
    "#     print('Best pass is %s, testing Avgcost is %s' % (best[0], best[1]))\n",
    "#     print('The classification accuracy is %.2f%%' % (float(best[2]) * 100))\n",
    "\n",
    "\n",
    "def infer(use_cuda,\n",
    "          save_dirname=None,\n",
    "          model_filename=None,\n",
    "          params_filename=None):\n",
    "    if save_dirname is None:\n",
    "        return\n",
    "\n",
    "    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "    exe = fluid.Executor(place)\n",
    "\n",
    "    def load_image(file):\n",
    "        im = Image.open(file).convert('L')\n",
    "        im = im.resize((28, 28), Image.ANTIALIAS)\n",
    "        im = numpy.array(im).reshape(1, 1, 28, 28).astype(numpy.float32)\n",
    "        im = im / 255.0 * 2.0 - 1.0\n",
    "        return im\n",
    "\n",
    "    cur_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    tensor_img = load_image(cur_dir + '/image/infer_3.png')\n",
    "\n",
    "    inference_scope = fluid.core.Scope()\n",
    "    with fluid.scope_guard(inference_scope):\n",
    "        # Use fluid.io.load_inference_model to obtain the inference program desc,\n",
    "        # the feed_target_names (the names of variables that will be feeded\n",
    "        # data using feed operators), and the fetch_targets (variables that\n",
    "        # we want to obtain data from using fetch operators).\n",
    "        [inference_program, feed_target_names,\n",
    "         fetch_targets] = fluid.io.load_inference_model(\n",
    "             save_dirname, exe, model_filename, params_filename)\n",
    "\n",
    "        # Construct feed as a dictionary of {feed_target_name: feed_target_data}\n",
    "        # and results will contain a list of data corresponding to fetch_targets.\n",
    "        results = exe.run(\n",
    "            inference_program,\n",
    "            feed={feed_target_names[0]: tensor_img},\n",
    "            fetch_list=fetch_targets)\n",
    "        lab = numpy.argsort(results)\n",
    "        print(\"Inference result of image/infer_3.png is: %d\" % lab[0][0][-1])\n",
    "\n",
    "\n",
    "def main(use_cuda, nn_type):\n",
    "    model_filename = None\n",
    "    params_filename = None\n",
    "    save_dirname = \"recognize_digits_\" + nn_type + \".inference.model\"\n",
    "\n",
    "    # call train() with is_local argument to run distributed train\n",
    "    train(\n",
    "        nn_type=nn_type,\n",
    "        use_cuda=use_cuda,\n",
    "        save_dirname=save_dirname,\n",
    "        model_filename=model_filename,\n",
    "        params_filename=params_filename)\n",
    "    infer(\n",
    "        use_cuda=use_cuda,\n",
    "        save_dirname=save_dirname,\n",
    "        model_filename=model_filename,\n",
    "        params_filename=params_filename)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    use_cuda = True\n",
    "    #predict = 'softmax_regression' # uncomment for Softmax\n",
    "    #predict = 'multilayer_perceptron' # uncomment for MLP\n",
    "    predict = 'convolutional_neural_network'  # uncomment for LeNet5\n",
    "    main(use_cuda=use_cuda, nn_type=predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 记录\n",
    "* numpy读取数据完成\n",
    "\n",
    "Todo:\n",
    "\n",
    "* TestTrain()\n",
    "* Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
