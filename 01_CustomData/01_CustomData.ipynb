{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标\n",
    "* 通过代码生成训练的图片和标签\n",
    "* 将自己的训练集合喂给PaddlePaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.random.random(size=(1,13)).astype('float32')\n",
    "#numpy.random.random(size=(1,1)).astype('float32')\n",
    "#print(a)\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy知识准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numpy.array([[1.1,2.2,3.3]],dtype='float32')\n",
    "\n",
    "#a = 4\n",
    "#b = [[a]]\n",
    "\n",
    "aa=np.empty([0,13],'float32')\n",
    "bb = [1.1,2.2,3.2,4.3,5,6,7,8,9,10,11,12,13]\n",
    "cc=[bb] \n",
    "aa = np.append(aa, cc,axis=0)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练数据准备\n",
    "图片按照需要存入\n",
    "```\n",
    "./img/num.png\n",
    "```\n",
    "记录文件 trainData.dt\n",
    "```\n",
    "./img/num.png,0\n",
    "./img/num.png,1\n",
    "```\n",
    "新建img目录\n",
    "\n",
    "* [ ] 代码生成目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "\n",
    "imgW = 28\n",
    "imgH = 28\n",
    "\n",
    "def generalRec():\n",
    "    img = np.ones((imgW,imgH),dtype=np.uint8)\n",
    "    InitX = random.randint(2,imgW-5)\n",
    "    InitY = random.randint(2,imgH-5)\n",
    "    RecW = random.randint(4,imgW-InitX-1)\n",
    "    RecH = random.randint(4,imgH-InitY-1)\n",
    "    cv.rectangle(img,(InitX,InitY),(RecW,RecH),255,1)\n",
    "#     #显示图片\n",
    "#     cv.namedWindow(\"img\")\n",
    "#     cv.imshow(\"img\",img)\n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()\n",
    "    return img\n",
    "\n",
    "\n",
    "    \n",
    "def generalCircle():\n",
    "    img = np.ones((imgW,imgH),dtype=np.uint8)\n",
    "    InitX = random.randint(5,imgW-5)\n",
    "    InitY = random.randint(5,imgH-5)\n",
    "    minDis = min(5,imgW-InitX,imgH-InitY)\n",
    "    r = random.randint(2,minDis)\n",
    "    cv.circle(img,(InitX,InitY),r,255,1)\n",
    "#     #显示图片\n",
    "#     cv.namedWindow(\"img\")\n",
    "#     cv.imshow(\"img\",img)\n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()\n",
    "    return img\n",
    "    \n",
    "\n",
    "def GenerateTrainData(genNum):\n",
    "    with open('trainData.dt','w') as f:\n",
    "        for i in range(genNum):\n",
    "            randBoo = random.choice([True,False])\n",
    "            if(randBoo):\n",
    "                # general rec\n",
    "                genImg = generalRec()\n",
    "                lineStr = \"./img/\"+i.__str__()+\".png,0\\n\"\n",
    "                f.write(lineStr)\n",
    "                cv.imwrite(\"./img/\"+i.__str__()+\".png\",genImg)\n",
    "            else:\n",
    "                # general circle\n",
    "                genImg = generalCircle()\n",
    "                lineStr = \"./img/\"+i.__str__()+\".png,1\\n\"\n",
    "                f.write(lineStr)\n",
    "                cv.imwrite(\"./img/\"+i.__str__()+\".png\",genImg)\n",
    "            \n",
    "        \n",
    "\n",
    "GenerateTrainData(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('trainData.dt') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        strSplit=line.split(',',1)\n",
    "        label_input=float(strSplit[1])\n",
    "        aa=numpy.empty([0,1],'float32')\n",
    "        aa = numpy.append(aa, [[label_input]],axis=0)\n",
    "        print(aa)\n",
    "        \n",
    "#        img = cv.imread(strSplit[0],cv.IMREAD_GRAYSCALE)\n",
    "#         npImg = np.reshape(img,(1,784))\n",
    "#         print(npImg)\n",
    "#         cv.namedWindow(\"img\")\n",
    "#         cv.imshow(\"img\",img)\n",
    "#         cv.waitKey(0)\n",
    "#         cv.destroyAllWindows()\n",
    "        line = f.readline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PaddlePadlle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train cost, Step 1, Cost 860.028503\n",
      "Train cost, Step 2, Cost 73699528.000000\n",
      "Train cost, Step 3, Cost 5575144898560.000000\n",
      "Train cost, Step 4, Cost 3612168159232000.000000\n",
      "Train cost, Step 5, Cost 1181186236605712564224.000000\n",
      "Train cost, Step 6, Cost 113870718149340934390677504.000000\n",
      "Train cost, Step 7, Cost 10082978098649916212403077382144.000000\n",
      "Train cost, Step 8, Cost 14609593939467829587911910898008064.000000\n",
      "Train cost, Step 9, Cost 3281871344954872226710874796526141440.000000\n",
      "Train cost, Step 10, Cost inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy\n",
    "import math\n",
    "import sys\n",
    "import cv2 as cv\n",
    "\n",
    "# For training test cost\n",
    "def train_test(executor, program, reader, feeder, fetch_list):\n",
    "    accumulated = 1 * [0]\n",
    "    count = 0\n",
    "    for data_test in reader():\n",
    "        outs = executor.run(\n",
    "            program=program, feed=feeder.feed(data_test), fetch_list=fetch_list)\n",
    "        accumulated = [x_c[0] + x_c[1][0] for x_c in zip(accumulated, outs)]\n",
    "        count += 1\n",
    "    return [x_d / count for x_d in accumulated]\n",
    "\n",
    "\n",
    "def main():\n",
    "    batch_size = 20\n",
    "    train_reader = paddle.batch(\n",
    "        paddle.reader.shuffle(paddle.dataset.uci_housing.train(), buf_size=500),\n",
    "        batch_size=batch_size)\n",
    "    test_reader = paddle.batch(\n",
    "        paddle.reader.shuffle(paddle.dataset.uci_housing.test(), buf_size=500),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    # feature vector of length 784\n",
    "    x = fluid.layers.data(name='x', shape=[784], dtype='float32')\n",
    "    y = fluid.layers.data(name='y', shape=[1], dtype='float32')\n",
    "    y_predict = fluid.layers.fc(input=x, size=1, act=None)\n",
    "\n",
    "    main_program = fluid.default_main_program()\n",
    "    startup_program = fluid.default_startup_program()\n",
    "\n",
    "    cost = fluid.layers.square_error_cost(input=y_predict, label=y)\n",
    "    avg_loss = fluid.layers.mean(cost)\n",
    "\n",
    "    sgd_optimizer = fluid.optimizer.SGD(learning_rate=0.001)\n",
    "    sgd_optimizer.minimize(avg_loss)\n",
    "\n",
    "    test_program = main_program.clone(for_test=True)\n",
    "\n",
    "    # can use CPU or GPU\n",
    "    use_cuda = True\n",
    "    place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "    exe = fluid.Executor(place)\n",
    "\n",
    "    # Specify the directory to save the parameters\n",
    "    params_dirname = \"fit_a_line.inference.model\"\n",
    "    num_epochs = 100\n",
    "\n",
    "    # main train loop.\n",
    "    feeder = fluid.DataFeeder(place=place, feed_list=[x, y])\n",
    "    exe.run(startup_program)\n",
    "\n",
    "    train_prompt = \"Train cost\"\n",
    "    test_prompt = \"Test cost\"\n",
    "    step = 0\n",
    "\n",
    "    exe_test = fluid.Executor(place)\n",
    "\n",
    "#     aa=numpy.empty([0,784],'float32')\n",
    "#     bb = [1.1,2.2,3.2,4.3,5,6,7,8,9,10,11,12,13]\n",
    "#     cc=[bb] \n",
    "#     aa = numpy.append(aa, cc,axis=0)\n",
    "    \n",
    "    \n",
    "    with open('trainData.dt') as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            strSplit=line.split(',',1)\n",
    "            img = cv.imread(strSplit[0],cv.IMREAD_GRAYSCALE)\n",
    "            npImg = numpy.reshape(img,(1,784))\n",
    "            label_input=float(strSplit[1])\n",
    "            npLabel=numpy.empty([0,1],'float32')\n",
    "            npLabel = numpy.append(npLabel, [[label_input]],axis=0)\n",
    "            avg_loss_value, = exe.run(\n",
    "                main_program,\n",
    "                feed={\n",
    "                       \"x\": npImg.astype('float32'),\n",
    "                       \"y\": npLabel.astype('float32')\n",
    "                },\n",
    "                fetch_list=[avg_loss])\n",
    "            step += 1\n",
    "            if step % 1 == 0:  # record a train cost every 10 batches\n",
    "                print(\"%s, Step %d, Cost %f\" %\n",
    "                      (train_prompt, step, avg_loss_value[0]))\n",
    "            line = f.readline()\n",
    "\n",
    "#            if step % 100 == 0:  # record a test cost every 100 batches\n",
    "#                test_metics = train_test(\n",
    "#                    executor=exe_test,\n",
    "#                    program=test_program,\n",
    "#                    reader=test_reader,\n",
    "#                    fetch_list=[avg_loss],\n",
    "#                    feeder=feeder)\n",
    "#                print(\"%s, Step %d, Cost %f\" %\n",
    "#                      (test_prompt, step, test_metics[0]))\n",
    "                # If the accuracy is good enough, we can stop the training.\n",
    "#                if test_metics[0] < 10.0:\n",
    "#                    break\n",
    "            \n",
    "\n",
    "#             if math.isnan(float(avg_loss_value[0])):\n",
    "#                 sys.exit(\"got NaN loss, training failed.\")\n",
    "#         if params_dirname is not None:\n",
    "#             # We can save the trained parameters for the inferences later\n",
    "#             fluid.io.save_inference_model(params_dirname, ['x'], [y_predict],\n",
    "#                                           exe)\n",
    "\n",
    "#     infer_exe = fluid.Executor(place)\n",
    "#     inference_scope = fluid.core.Scope()\n",
    "\n",
    "    # infer\n",
    "#  \n",
    "#     with fluid.scope_guard(inference_scope):\n",
    "#         [inference_program, feed_target_names, fetch_targets\n",
    "#          ] = fluid.io.load_inference_model(params_dirname, infer_exe)\n",
    "#         batch_size = 10\n",
    "\n",
    "#         infer_reader = paddle.batch(\n",
    "#             paddle.dataset.uci_housing.test(), batch_size=batch_size)\n",
    "\n",
    "#         infer_data = next(infer_reader())\n",
    "#         infer_feat = numpy.array(\n",
    "#             [data[0] for data in infer_data]).astype(\"float32\")\n",
    "#         infer_label = numpy.array(\n",
    "#             [data[1] for data in infer_data]).astype(\"float32\")\n",
    "\n",
    "#         assert feed_target_names[0] == 'x'\n",
    "#         results = infer_exe.run(\n",
    "#             inference_program,\n",
    "#             feed={feed_target_names[0]: numpy.array(infer_feat)},\n",
    "#             fetch_list=fetch_targets)\n",
    "\n",
    "#         print(\"infer results: (House Price)\")\n",
    "#         for idx, val in enumerate(results[0]):\n",
    "#             print(\"%d: %.2f\" % (idx, val))\n",
    "\n",
    "#         print(\"\\nground truth:\")\n",
    "#         for idx, val in enumerate(infer_label):\n",
    "#             print(\"%d: %.2f\" % (idx, val))\n",
    " \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "* 自己生产的数据可以通过opencv和np喂给Paddle\n",
    "* 训练效果有问题 \n",
    "    * 分类和回归问题的目标函数和损失函数不一样 以二维为例\n",
    "        * 回归是为了找到拟合数据的曲线\n",
    "        * 分类是为了找到数据的分割线\n",
    "        \n",
    " Todo：\n",
    " * [ ] 使用FC、SoftMax网络做分类\n",
    " * [ ] 数据读取改用自定义Reader的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
